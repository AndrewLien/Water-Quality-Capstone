---
title: "Final.Report"
author: "Andrew Lien"
date: "July 23, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r include = F, message = F,echo = F}
library(ggplot2)
library(dplyr)
library(tidyr)
library(magrittr)
library(RColorBrewer)
library(scales)
library(binr)
library(caTools)
library(ROCR)
library(effects)
```
# **INTRODUCTION**

## Background

Bathing or swimming in bodies of water that have significant e. coli levels pose a health risk. E. coli is often tested with a biological assay that can take some time to yield results. 

## Proposal

To get advance warning of risks of high e. coli levels more quickly, alternative chemical tests that can yield results faster can be used to predict high e. coli levels.

## Approach

This project aims to use data from the [UK Environment Agency](http://environment.data.gov.uk/water-quality/view/landing) to search for correlations between the e. coli concentration and the results of various determinands, using data from 2013-2017.

The raw data is organized into tidy format using tidyr and dplyr, such that different tests that have the same time, place, and material type are collapsed into the same observation. This data is then explored using ggplot2 to identify which variables are correlated to each other and which are most strongly correlated to e. coli levels. By identifying variables that have significant relationships to e. coli concentration, a logistical regression model can be created to predict whether e. coli concentration will be above or below safe levels.

## Deliverables

The objective of this project is to develop a model that can predict, based on different test results, whether a given sample will have an e. coli concentration above safe levels, within a certain confidence level.

**Note that because this data is so large, the sections "COMBINING ANNUAL DATA" and "FILTERING AND TIDYING DATA" are run separately to generate the file "water.ecoli.csv", instead of being run in this script. This is a limitation that arises due to limited computing power.**

# **COMBINING ANNUAL DATA**

Data from the [UK Environment Agency](http://environment.data.gov.uk/water-quality/view/landing) is imported and combined to make one large data set. Some irrelevant columns are removed and some of the remaining columns are renamed to make them simpler to refer to. The remaining columns are:

- time
- determinand.label
- result
- resultunit
- materialtype 
- easting
- northing 

```{r echo = F, eval = F}
water2013 <- read.csv("2013.csv", stringsAsFactors = F)
water2014 <- read.csv("2014.csv", stringsAsFactors = F)
water2015 <- read.csv("2015.csv", stringsAsFactors = F)
water2016 <- read.csv("2016.csv", stringsAsFactors = F)
water2017 <- read.csv("2017.csv", stringsAsFactors = F)
water.raw <- rbind(water2013, water2014, water2015, water2015, water2016, water2017)
water.raw$sample.samplingPoint <- NULL
water.raw$codedResultInterpretation.interpretation <- NULL
water.raw$sample.samplingPoint.notation <- NULL
water.raw$sample.samplingPoint.label <- NULL
water.raw$determinand.notation <- NULL
water.raw$determinand.definition <- NULL
water.raw$resultQualifier.notation <- NULL
water.raw$sample.purpose.label <- NULL
water.raw$sample.isComplianceSample <- NULL
water.raw$X.id <- NULL
colnames(water.raw) <- c("time", "determinand.label", "result", "resultunit", "materialtype", "easting", "northing")
```

# **FILTERING AND TIDYING**

## Filtering by Material Type

Because this dataset is large (> 13 GB), it's unfeasible to perform the functions spread() and aggregate(), which are necessary to clean and analyze the data. The scope of this project is narrowed down by limiting the number of material types and the number of determinands that are considered so that these functions can be used to tidy the data. Below are the 10 most frequenctly occuring material types in this data set.

```{r echo = F, eval = F}
water.raw <- read.csv("water.raw.csv", stringsAsFactors = F)
table(water.raw$materialtype) %>% sort(decreasing = T) %>% head(10)
```

The top 4 material types "RIVER / RUNNING SURFACE WATER", "SEA WATER", "ESTUARINE WATER", and "POND / LAKE / RESERVOIR WATER" are filtered for, skipping over "FINAL SEWAGE EFFLUENT" because it's not a type of water that people will swim in.

## Filtering by Determinand

The second filter applied is generated by creating a list of the most significant determinands, chosen by a combination of which tests were performed the most frequently and by reading in literature which were most likely to have an efects on e. coli concentration. Some of the frequently occuring determinands were selected on the basis that there was literature to support a relationship to e. coli. The literature along with a short summary of their conclusions can be found below:

- Copper tends to inhibit e. coli growth [1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4249004/) [2](https://www.ncbi.nlm.nih.gov/pubmed/27280608)
- Dissolved iron tends to promote e. coli growth [3](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1214678/) [4](https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1472-765X.2006.01895.x)
- Cadmium inhibits e. coli growth, while zinc has little effect [5](https://www.ncbi.nlm.nih.gov/pubmed/1795651)
- pH, temperature, and dissolved oxygen affect e. coli growth [6](http://www.gatewaycoalition.org/files/hidden/react/ch4/4_4f.htm) [7](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3605374/)
- High levels of ammonium can be toxic to bacteria [7](https://link.springer.com/article/10.1007%2Fs00284-005-0370-x)
- Higher phosphorus concentrations prolong the survival of e. coli [8](http://aem.asm.org/content/73/11/3755.full)
- E. coli rely on reducing nitrate to ammonia when there's a lack of oxygen [9](https://www.ncbi.nlm.nih.gov/pubmed/8919448)

The selected determinands are:

- **Temp Water**: Temperature of the water
- **pH**: Values closer to 1 indicate acidity and those closer to 14 indicate basicity. Neutral water has pH 7.
- **Nitrite-N**: Concentration of nitrogen originating from nitrites.
- **Orthophospht**: Concentration of orthophosphates.
- **O Diss %sat**: Only so much oxygen can be dissolved in water before the water is saturated. This is a measure of the concentration of dissolved oxygen in the water sample as a percentage of that saturated level.
- **Nitrate-N**: Concentration of nitrogen originating from nitrates.
- **Oxygen Diss**: This is the absolute concentration of dissolved oxygen in the water.
- **E.coli C-MF**: This is the concentration of e. coli bacteria found in the water sample.
- **SALinsitu**: This is the salinity of sample. Salinity is the amont of salt dissolved in the sample.
- **Cu Filtered**: This is the concentration of copper detected in the sample.
- **BOD ATU**: This is a measure of the amount of oxygen required by aerobic biological organisms in water to break down organic material present in the water sample.
- **Ni-Filtered**: This is the concentration of nickel detected in the sample.
- **Bathers 100m**: This is the number of bathers per 100m of shoreline. 
- **Beach Users**: This is the total number of beach users. 


```{r echo = F, eval = F}
water.ecoli <- filter(water.raw, water.raw$materialtype == "RIVER / RUNNING SURFACE WATER" | water.raw$materialtype == "SEA WATER" | water.raw$materialtype == "ESTUARINE WATER" | water.raw$materialtype == "POND / LAKE / RESERVOIR WATER")
water.ecoli$materialtype %<>% as.factor()

# New determinand selection criteria
significantdeterminands <- c("Temp Water", "pH", "Nitrite-N", "Orthophospht", "O Diss %sat", "Nitrate-N", "Oxygen Diss", "E.coli C-MF", "SALinsitu", "Cu Filtered", "BOD ATU", "Cu Filtered", "Ni- Filtered", "Bathers 100m", "Beach Users")

water.ecoli <- filter(water.ecoli, match(water.ecoli$determinand.label, significantdeterminands) > 0)
```

## Exploring Material Type Composition

Samples from each differing material type likely has different tests that are performed frequently, so this is visualized with a stacked bar plot. This graph makes it evident that each material type has different determinands frequently tested on it, so some material types will be better suited for answering specific questions and others will be ill-suited. The relationships between each of the determinands are to be explored in Exploratory Analysis.

```{r echo = F, eval = F}
rivercomponents <- table(filter(water.ecoli, water.ecoli$materialtype == "RIVER / RUNNING SURFACE WATER")$determinand.label)
seacomponents <- c(table(filter(water.ecoli, water.ecoli$materialtype == "SEA WATER")$determinand.label))
estuarycomponents <- c(table(filter(water.ecoli, water.ecoli$materialtype == "ESTUARINE WATER")$determinand.label))
lakecomponents <- table(filter(water.ecoli, water.ecoli$materialtype == "POND / LAKE / RESERVOIR WATER")$determinand.label)
componentstable <- as.data.frame(cbind(seacomponents, estuarycomponents, rivercomponents, lakecomponents))
rownames(componentstable) <- rownames(rivercomponents)
componentstable

componentstable <- sweep(componentstable, MARGIN = 2, FUN = "/", STATS = colSums(componentstable))
componentstable <- cbind(row.names(componentstable), componentstable)
colnames(componentstable)[1] <- "determinand"
componentstable <- gather(componentstable, key = "materialtype", value = "percent of tests", 2:5)
componentstable$materialtype %<>% as.factor()
componentstable %<>% arrange(`percent of tests`)
ggplot(componentstable, aes(x = materialtype, y = `percent of tests`, fill = determinand)) + 
  geom_bar(position = "fill", stat = "identity") + 
  scale_fill_manual(values = colorRampPalette(brewer.pal(9, "Set1"))(length(unique(componentstable$determinand)))) + 
  scale_y_continuous(label = percent) + 
  ggtitle("How often is each determinand tested for each material type?")
```

## Tidying the Dataset

With a smaller filesize, the spread() function succeeds, resulting in a manageable filesize of 425.6 MB. After applying aggregate() and selecting only observations that have a corresponding e. coli measurement, the finalized dataset is an easily manageble 14.8 MB. In preparation of creating a logistical regression model, an additional column is added to indicate whether a given observation has an e. coli measurement higher than considered safe, 900 units per 100 mL. The data wrangling is now complete and is saved and exported as "water.ecoli.csv".

```{r echo = F, eval = F}
# Spread according to the column "determinand.label" to get tidy data.
water.ecoli$determinand.label %<>% as.factor()
water.ecoli$resultunit %<>% as.factor()
water.ecoli$id <- 1:nrow(water.ecoli)
water.ecoli <- spread(water.ecoli, key = determinand.label, value = result)
water.ecoli$id <- NULL
          
# Remove duplicate rows 
water.ecoli <- unique(water.ecoli)

# Adding resultunit to columnsames.
for (i in 6:length(water.ecoli)) {
  position <- grep(x = is.na(water.ecoli[,i]), pattern = FALSE)[1]
  unit <- water.ecoli[position, "resultunit"]
  colnames(water.ecoli)[i] <- paste(colnames(water.ecoli)[i], unit, sep = ".")
}
water.ecoli$resultunit <- NULL

# Aggregate rows. 
water.ecoli <- aggregate(water.ecoli[,5:length(water.ecoli)], water.ecoli[,1:4], FUN = sum, na.rm = T)
water.ecoli[water.ecoli == 0] <- NA

# Filter to rows that have value for e. coli
water.ecoli <- filter(water.ecoli, is.na(water.ecoli$`E.coli C-MF.no/100ml`) == F)

str(water.ecoli)
```

Each observation is categorized as either having an e. coli measurement greater or less than the water quality limit of 900 no/100mL before exporting the file.
```{r, eval = F, echo = F}
water.ecoli$E.coli.C.MF.conform <- water.ecoli$`E.coli C-MF.no/100ml` < 900
write.csv(x = water.ecoli, file = "water.ecoli.csv", row.names = F)
```

# **EXPLORATORY ANALYSIS**

```{r echo = F, message = F, include = F}
water.ecoli <- read.csv("water.ecoli.csv", stringsAsFactors = F)
water.ecoli$materialtype %<>% as.factor()
water.ecoli$time %<>% as.POSIXct(format = "%Y-%m-%dT%H:%M:%S")
```

In order to better understand the data and how to best create a predictive model, the data must first be explored. This is done in a systematic manner, as outlined below:

1. Collinearity
  a. Correlation Matrix
  b. Investigating Correlated Variables
  c. Removing Correlated Variables
2. Testing Frequencies
3. Investigating Relationships to E. Coli
4. Investigating Relationships to Location
5. Investigating Relationships to Time

# Collinearity

## a. Correlation Matrix

A correlation matrix shows correlation coefficients between each pair of variables in the dataset. Instead of having values ranging from -1 to +1, these values are converted to grayscale colors, ranging from white to black. Having the correlation matrix converted to a heatmap makes it easier to see that some pairs of variables are highly correlated. White cells correspond to values close to -1 and black cells correspond to values close to +1.

```{r echo = F, warning = F}
cor.table <- cor(water.ecoli[,5:length(water.ecoli)], use = "pairwise.complete.obs")
cor.table <- as.data.frame(cbind(rownames(cor.table), cor.table))
cor.table <- gather(cor.table, key = "V2", value = "cor.value", 2:length(cor.table))
cor.table$cor.value %<>% as.numeric()
ggplot(cor.table, aes(x = V1, y = V2)) +
  geom_tile(aes(fill = cor.value), color = "white") +
  scale_fill_gradient(low = "white", high = "black") +
  ggtitle("Correlation Heat Map") +
  xlab("Determinand1") +
  ylab("Determinand2") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## b. Investigating Correlated Variables

Variable pairs that showed a strong relationship in the correlation matrix heat map are plotted using the package ggplot2, revealing finer structures in the data.

### Oxygen.Diss.mg.l and O.Diss..sat..

```{r echo = F, warning = F}
ggplot(water.ecoli, aes(x = Oxygen.Diss.mg.l, y = O.Diss..sat.., color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scales = "free")
```

Both of these determinands are different measurement methods for the same physical property, dissolved oxygen in water, so it makes sense that they are strongly correlated. Only One needs to be kept.

### Oxygen.Diss.mg.l and Temp.Water.cel

```{r echo = F, warning = F}
ggplot(water.ecoli, aes(x = Temp.Water.cel, y = Oxygen.Diss.mg.l, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scales = "free")
```

This negative correlation makes sense, because the solubility of gas in liquid is known to decrease as the temperature of the liquid increases. Though they aren't perfectly negatively correlated, this suggests that it may be better to include only one of these two variables instead of both in a predictive model.

### SALinsitu.ppt and Cu.Filtered.ug.l


```{r echo = F, warning = F}
ggplot(water.ecoli, aes(x = SALinsitu.ppt, y = Cu.Filtered.ug.l, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~materialtype, scales = "free")
```

The positive correlation between copper concentration and salinity in estuarine water suggests that copper might be one of the main salt constituents in estuarine water. However, due to the low sample size of points relating copper and salinity, this correlation isn't statistically reliable.

## c. Removing Correlated Variables

```{r}
water.ecoli$O.Diss..sat.. <- NULL
```

# 2. Testing Frequencies

Each of the determinands are tested with different frequencies based on material type. This is visualized below to better understand the differences between each material type.

Note to self: This plot still needs to be fixed to 1) show bars in order of largest to smallest... will get back to it later.

```{r echo = F, message = F, warning = F}
frequencytable <- aggregate(x = is.na(select(water.ecoli, c(5:18))) == F, by = select(water.ecoli, 2), FUN = sum)
frequencytable <- t(frequencytable)
colnames(frequencytable) <- frequencytable[1,]
frequencytable <- as.data.frame(frequencytable[-1,])
frequencytable <- cbind(rownames(frequencytable), frequencytable)
colnames(frequencytable)[1] <- "determinand"
frequencytable <- gather(frequencytable, key = "materialtype", value = "count", 2:5)
frequencytable$materialtype %<>% as.factor()
frequencytable$count %<>% as.numeric()

ggplot(frequencytable, aes(x = materialtype, y = count, fill = determinand)) + 
  geom_bar(position = "fill", stat = "identity") +
  scale_fill_manual(values = colorRampPalette(brewer.pal(9, "Set1"))(length(unique(frequencytable$determinand)))) +
  scale_y_continuous(label = percent) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# 3. Investigating Relationships to E. Coli
Instead of comparing the relationship between the magnitude of e. coli or pH, it should be the frequency of e. coli < 900 per region of T or pH.

## Water Temperature, pH, and Dissolved Oxygen
Plotting each of these variables against the count of observations that have e. coli concentrations above or below regulatory levels shows that each interval has different ratios of conformance to nonconformance, indicating that these variables have some impact on e. coli growth; however, these plots also reveal that there are fewer testing points at high and low values of each of these variables, making any logistical regression model based on these TRUE/FALSE frequencies less reliable at those regions.
```{r echo = F, warning = F}
# Water Temperature
water.ecoli.Temp <- select(filter(water.ecoli, is.na(water.ecoli$Temp.Water.cel) == 0), c(1:4, "E.coli.C.MF.no.100ml", "Temp.Water.cel", "E.coli.C.MF.conform"))
water.ecoli.Temp <- cbind(water.ecoli.Temp, cut(water.ecoli.Temp$Temp.Water.cel, 30))
colnames(water.ecoli.Temp)[8] <- "bin"
ggplot(water.ecoli.Temp, aes(x = bin)) +
  geom_bar(aes(fill = factor(E.coli.C.MF.conform)), width = 0.9, stat = "count", position = "dodge") +
  scale_color_discrete(name = "conforms", breaks = c(T, F), labels = c("True", "False")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ materialtype, scales = "free") +
  ggtitle("E. Coli Conformance count and Water Temperature")

# pH
water.ecoli.pH <- select(filter(water.ecoli, is.na(water.ecoli$pH.phunits) == 0), c(1:4, "E.coli.C.MF.no.100ml", "pH.phunits", "E.coli.C.MF.conform"))
water.ecoli.pH <- cbind(water.ecoli.pH, cut(water.ecoli.pH$pH.phunits, 30))
colnames(water.ecoli.pH)[8] <- "bin"
ggplot(water.ecoli.pH, aes(x = bin)) +
  geom_bar(aes(fill = factor(E.coli.C.MF.conform)), width = 0.9, stat = "count", position = "dodge") +
  scale_color_discrete(name = "conforms", breaks = c(T, F), labels = c("True", "False")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ materialtype, scales = "free") +
  ggtitle("E. Coli Conformance count and pH")

# Dissolved Oxygen
water.ecoli.oxygen.diss <- select(filter(water.ecoli, is.na(water.ecoli$Oxygen.Diss.mg.l) == 0), c(1:4, "E.coli.C.MF.no.100ml", "Oxygen.Diss.mg.l", "E.coli.C.MF.conform"))
water.ecoli.oxygen.diss <- cbind(water.ecoli.oxygen.diss, cut(water.ecoli.oxygen.diss$Oxygen.Diss.mg.l, 30))
colnames(water.ecoli.oxygen.diss)[8] <- "bin"
ggplot(water.ecoli.oxygen.diss, aes(x = bin)) +
  geom_bar(aes(fill = factor(E.coli.C.MF.conform)), width = 0.9, stat = "count", position = "dodge") +
  scale_color_discrete(name = "conforms", breaks = c(T, F), labels = c("True", "False")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ materialtype, scales = "free") +
  ggtitle("E. Coli Conformance count and Dissolved Oxygen")
```

```{r eval = F, echo = F, warning = F}
# These variables seemed to have little to no relationship with e. coli and will not be used to predict e. coli.
ggplot(water.ecoli, aes(x = BOD.ATU.mg.l, y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scale = "free")
ggplot(water.ecoli, aes(x = Cu.Filtered.ug.l, y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scale = "free")
ggplot(water.ecoli, aes(x = Ni..Filtered.ug.l, y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scale = "free")
ggplot(water.ecoli, aes(x = Nitrate.N.mg.l, y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scale = "free")
ggplot(water.ecoli, aes(x = Orthophospht.mg.l, y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scale = "free")
ggplot(water.ecoli, aes(x = SALinsitu.ppt, y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2) +
  facet_wrap(~materialtype, scale = "free")
# Salinity... checking to see how the distribution breaks down between conform/non-conform.
water.ecoli.sal <- select(filter(water.ecoli, is.na(water.ecoli$SALinsitu.ppt) == 0), c(1:4, "E.coli.C.MF.no.100ml", "SALinsitu.ppt", "E.coli.C.MF.conform"))
water.ecoli.sal <- cbind(water.ecoli.sal, cut(water.ecoli.sal$SALinsitu.ppt, 30))
colnames(water.ecoli.sal)[8] <- "bin"
ggplot(water.ecoli.sal, aes(x = bin)) +
  geom_bar(aes(fill = factor(E.coli.C.MF.conform)), width = 0.9, stat = "count", position = "dodge") +
  scale_color_discrete(name = "conforms", breaks = c(T, F), labels = c("True", "False")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  facet_wrap(~ materialtype, scales = "free") +
  ggtitle("E. Coli Conformance count and Salinity")
```

# 4. Investigating Relationships to Location

```{r echo = F, warning = F}
ggplot(water.ecoli, aes(x = easting, y = northing, color = materialtype)) +
  geom_point(alpha = 0.2)
```

As expected, most pond/river sampling locations are farther inland and all seawater samples are taken along the coast of the UK.

# 5. Investigating Relationships to Time

```{r echo = F, warning = F}
# Time and Water T
ggplot(water.ecoli, aes(x = time, y = Temp.Water.cel, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2)
# BOD ATU
ggplot(water.ecoli, aes(x = time, y = BOD.ATU.mg.l, color = E.coli.C.MF.conform)) +
  geom_point(alpha = 0.2)
```

The relationships of both BOD ATU and Temp Water to time show that seasons do have an effect on e. coli growth. This is important information that can be used to improve the predictive model.

# **MODELING**

```{r echo = F, message = F, include = F}
# Setup
water.ecoli <- read.csv("water.ecoli.csv", stringsAsFactors = F)
water.ecoli$materialtype %<>% as.factor()
water.ecoli$time %<>% as.POSIXct(format = "%Y-%m-%dT%H:%M:%S")
water.ecoli$O.Diss..sat.. <- NULL
```

## **Setup**

With the dataset reorganized into tidy format and the major significant variables identified, a model can be constructed. This model will be a logistical regression that predicts whether a water sample will have an e. coli concentration greater than safe levels (900 units per 100 mL) with a certain percentage of accuracy, based on the values of a few other select variables. Some of these features are information that needs to be extracted from an existing variable before it can be a significant contributor to the model. 

### Feature Engineering 

The variables that can be engineered to yield new new information are time, pH, and water temperature.

1. "time", which is a value, is converted into "seasons", which is a 4-level factor. This is done because in exploratory analysis, it was observed that several other variables, including water temperature and dissolved oxygen, oscillate according to the time of year the water sample is taken. 
```{r}
water.ecoli$season <- substr(water.ecoli$time, 6, 7)
water.ecoli$season <- gsub(pattern = "09|10|11", replacement = "fall", x = water.ecoli$season)
water.ecoli$season <- gsub(pattern = "12|01|02", replacement = "winter", x = water.ecoli$season)
water.ecoli$season <- gsub(pattern = "03|04|05", replacement = "spring", x = water.ecoli$season)
water.ecoli$season <- gsub(pattern = "06|07|08", replacement = "summer", x = water.ecoli$season)
```

2. "pH.phunits", which is a value, is converted into "pH.ecolirange", which is a logical statement, either TRUE or FALSE. It was observed in exploratory analysis that there tended to be a higher concentration of water samples that had an e. coli level exceeding the 900 no/100ml threshold around the mean. Because the pH exhibited a normal distibution pattern when plotted against e. coli concentration, the majority of water sample with non-conforming e. coli levels were centered around that mean. For that reason, water samples that have a pH close to the mean have a relatively higher chance of also having an e. coli level exceeding the threshold. 

The plot below shows that the majority of non-conforming e. ocli measurements are close to the mean of the group, forming a pattern that resembles a normal distribution.
```{r warning = F, echo = F}
ggplot(water.ecoli, aes(x = pH.phunits,  y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) + geom_point(alpha = 0.3)
```

"pH.phunits" is divided into two groups: within mean +/- 2*sd of non-conforming samples or not within that range.
```{r}
nonconform.pH <- filter(water.ecoli, is.na(water.ecoli$pH.phunits) == F & water.ecoli$E.coli.C.MF.conform == F)
nonconform.pH.mean <- mean(nonconform.pH$pH.phunits)
nonconform.pH.sd <- sd(nonconform.pH$pH.phunits)
water.ecoli$pH.ecolirange <- ifelse(water.ecoli$pH.phunits < nonconform.pH.mean + 2*nonconform.pH.sd & water.ecoli$pH.phunits > nonconform.pH.mean - 2*nonconform.pH.sd, T, F)
```

3. "Temp.Water.cel", which is a value, is converted into "temp.ecolirange", which is a logical statement, either TRUE or FALSE. Siimlar to pH.phunits, Temp.Water.cel also exhibited a normal distribution pattern when plotted against e. coli concentration. However, because the distribution is slightly negatively skewed, the median is used as the central point of the distribution. Whether a given point is within 2 standard deviations of the median is assigned TRUE or FALSE. 

The plot below shows that the majority of non-conforming e. coli measurements are close to the mean of the group, forming a pattern that resembles a negatively skewed normal distribution.
```{r warning = F, echo = F}
ggplot(water.ecoli, aes(x = Temp.Water.cel,  y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) + geom_point(alpha = 0.3)
```

The median is used instead of mean because this is a negatively skewed normal distribution: the median is closer to the maximum of the arch of the normal distribution than the mean. 

```{r}
nonconform.temp <- filter(water.ecoli, is.na(water.ecoli$Temp.Water.cel) == F & water.ecoli$E.coli.C.MF.conform == F)
nonconform.temp.mean <- median(nonconform.temp$Temp.Water.cel)
nonconform.temp.sd <- sd(nonconform.temp$Temp.Water.cel)
water.ecoli$temp.ecolirange <- ifelse(water.ecoli$Temp.Water.cel < nonconform.temp.mean + 2*nonconform.temp.sd & water.ecoli$Temp.Water.cel > nonconform.temp.mean - 2*nonconform.temp.sd, T, F)
```

### Normalization

Because many of the variables are in different units, the data needs to be normalized before a meaningful logistical regression model can be built.

```{r}
mean <- mapply(water.ecoli[,7:17], FUN = "mean", na.rm = T)
stdev <- mapply(water.ecoli[,7:17], FUN = "sd", na.rm = T)
water.ecoli[,7:17] %<>% sweep(., 2, FUN = "-", mean) %>% sweep(., 2, FUN = "/", stdev)
```

### Splitting the dataset into training and testing sets
```{r}
set.seed(123)
split.labels <- sample.split(Y = water.ecoli[,1], SplitRatio = 1/2)
data.train <- subset(water.ecoli, split.labels == T)
data.test <- subset(water.ecoli, split.labels == F)
```

**The model generation and evaluation process is the same for each of the models, so the full code is shown only for model1, and only the results are shown for the following models. At the very end of this file is a summary table that compares significant aspects of each model.**

## **model1 [SALinsitu.ppt + Oxygen.Diss.mg.l]**

This is a baseline model, created with as few variables as possible that also creates a model that has a reasonable accuracy. The number of variables used in this model is limited to

1. Avoid overfitting
2. Keep as many data points as possible. What's unique about this data set is that many rows have NAs for several testing results. Each row has NAs in different positions. The glm() modeling function only includes an observation as a data point if it has a non-NA value is each variable's position. By increasing the nunmber of variables in the model, the number of non-NA variables required also increases, thereby decreasing the number of observations that the model can use asa valid test point. By selecting only a few variables, the sample size is kept as large as possible to improve the statistical significance of the results.

To be able to compare the raw data set and the prediction, they need to be the same length. Since the glm() excludes rows that have NA in any of the specified variables, the raw data needes to be filtered to only rows that fit that criteria. Problem with this is that if there are too many criteria included, then there will be very few rows that match the criteria. The model can then be generated using the glm() function. 

```{r}
data.train1 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F)
model1 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l, data = data.train1, family = "binomial")
summary(model1)
```

### ROC curve

To evaluate the effectiveness of the model, an ROC curve can be used. This shows how by varying the threshold level, it's possible to vary the amount of false po sitives and false negatives the model scores when tested on a test data set. The package ROCR is used to not only generate the ROC curve, but also to retrieve the area under the curve (AUC), which is also a metric used to evalute the effectiveness of the model. The closer the area under the curve is to 1, the better, and the lower the value, the less effective. This result is saved to be compared to the AUC values of other models to be created.
```{r warning = F}
# predict() can't be used if there are NAs included, so rows with NA in either SALinsitu.ppt or Oxygen.Diss.mg.l need to be filtered out. To test the out-of-sample performance of this model, predict() is used on the data.test, which was not used to create the model. 
data.test1 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F)
# predict() can now be used. 
testsize1 <- nrow(data.test1)
train.predict1 <- predict(model1, type = "response", newdata = data.test1)

ROCR.pred1 <- prediction(train.predict1, data.test1$E.coli.C.MF.conform)
ROCR.perf1 <- performance(ROCR.pred1, "tpr", "fpr")
plot(ROCR.perf1, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
# According to the plot, t = 0.7 yields the more desirable balance of sensitivity and specificity. In this case, higher sensitivity is desired because a false negative leads to higher than expected e. coli levels and the associated public health risks.

# ROC area under curve
AUC1 <- performance(ROCR.pred1, "auc")
AUC1 <- as.numeric(AUC1@y.values)
AUC1
```

### Confusion Matrix

A confusion matrix is a way to organize a model's results of testing with a test data set. The model's predicted outcomes of whether an observation will have an e. coli concentration above or below the safety level of 900 units per 100ml is not always going to correct. Across the x-axis is the model's predicted outcome, and down the y-axis is the dataset's actual value for e. coli conformance. By manipulating these results, a set of useful metrics can be derived for evaluating the effectiveness of the model. For this project, the metrics of interest are sensitivity, the false positive rate, and accuracy. 
```{r}
# Confusion matrix with t = 0.7
confusionmatrix1<- table(data.test1$E.coli.C.MF.conform, train.predict1 > 0.7)
confusionmatrix1
sensitivity1 <- confusionmatrix1[2,2]/(confusionmatrix1[2,2] + confusionmatrix1[2,1])
accuracy1 <- (confusionmatrix1[1,1] + confusionmatrix1[2,2])/sum(confusionmatrix1)
falsepositive1 <- confusionmatrix1[1,2]/(confusionmatrix1[1,2] + confusionmatrix1[1,1])
sensitivity1
accuracy1
falsepositive1
```

### F1-score

An additional metric that can be derived from the confusion matrix is the F1-score. This is the harmonic mean of the precision and recall. The closer this value is to 1, the better the model. 

```{r}
# F1-score = 2/(1/recall + 1/precision)
# precision = TP/(TP + FP)
# recall = TP/(TP + FN)

precision1 <- confusionmatrix1[2,2]/(confusionmatrix1[2,2] + confusionmatrix1[2,1])
recall1 <- confusionmatrix1[2,2]/(confusionmatrix1[2,2] + confusionmatrix1[1,2])
f1score1 <- 2/(1/recall1 + 1/precision1)
f1score1
```

# **model2 [SALinsitu.ppt + Oxygen.Diss.mg.l*season]**

### Creating model2
```{r echo = F}
data.train2 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F)

model2 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l*season, data = data.train2, family = "binomial")
summary(model2)
```

### ROC curve

```{r warning = F, echo = F}
data.test2 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F & is.na(data.test$season) == F)
testsize2 <- nrow(data.test2)
train.predict2 <- predict(model2, type = "response", newdata = data.test2)

ROCR.pred2 <- prediction(train.predict2, data.test2$E.coli.C.MF.conform)
ROCR.perf2 <- performance(ROCR.pred2, "tpr", "fpr")
plot(ROCR.perf2, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC2 <- performance(ROCR.pred2, "auc")
AUC2 <- as.numeric(AUC2@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix2<- table(data.test2$E.coli.C.MF.conform, train.predict2 > 0.6)
confusionmatrix2
sensitivity2 <- confusionmatrix2[2,2]/(confusionmatrix2[2,2] + confusionmatrix2[2,1])
accuracy2 <- (confusionmatrix2[1,1] + confusionmatrix2[2,2])/sum(confusionmatrix2)

precision2 <- confusionmatrix2[2,2]/(confusionmatrix2[2,2] + confusionmatrix2[2,1])
recall2 <- confusionmatrix2[2,2]/(confusionmatrix2[2,2] + confusionmatrix2[1,2])
f1score2 <- 2/(1/recall2 + 1/precision2)
falsepositive2 <- confusionmatrix2[1,2]/(confusionmatrix2[1,2] + confusionmatrix2[1,1])
```

# **model3 [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange + temp.ecolirange]**

### Creating model3
```{r echo = F}
data.train3 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F & is.na(data.train$pH.ecolirange) == F & is.na(data.train$temp.ecolirange) == F)

model3 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange + temp.ecolirange, data = data.train3, family = "binomial")
summary(model3)
```

### ROC curve

```{r warning = F, echo = F}
data.test3 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F & is.na(data.test$pH.ecolirange) == F & is.na(data.test$temp.ecolirange) == F)
testsize3 <- nrow(data.test3)
train.predict3 <- predict(model3, type = "response", newdata = data.test3)

ROCR.pred3 <- prediction(train.predict3, data.test3$E.coli.C.MF.conform)
ROCR.perf3 <- performance(ROCR.pred3, "tpr", "fpr")
plot(ROCR.perf3, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC3 <- performance(ROCR.pred3, "auc")
AUC3 <- as.numeric(AUC3@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix3<- table(data.test3$E.coli.C.MF.conform, train.predict3 > 0.5)
confusionmatrix3
sensitivity3 <- confusionmatrix3[2,2]/(confusionmatrix3[2,2] + confusionmatrix3[2,1])
accuracy3 <- (confusionmatrix3[1,1] + confusionmatrix3[2,2])/sum(confusionmatrix3)

precision3 <- confusionmatrix3[2,2]/(confusionmatrix3[2,2] + confusionmatrix3[2,1])
recall3 <- confusionmatrix3[2,2]/(confusionmatrix3[2,2] + confusionmatrix3[1,2])
f1score3 <- 2/(1/recall3 + 1/precision3)
falsepositive3 <- confusionmatrix3[1,2]/(confusionmatrix3[1,2] + confusionmatrix3[1,1])
```

# **model4 [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange]**

### Creating model4
```{r echo = F}
data.train4 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F & is.na(data.train$pH.ecolirange) == F)
model4 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange, data = data.train4, family = "binomial")
summary(model4)
```

### ROC curve

```{r warning = F, echo = F}
data.test4 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F & is.na(data.test$pH.ecolirange) == F)
testsize4 <- nrow(data.test4)
train.predict4 <- predict(model4, type = "response", newdata = data.test4)

ROCR.pred4 <- prediction(train.predict4, data.test4$E.coli.C.MF.conform)
ROCR.perf4 <- performance(ROCR.pred4, "tpr", "fpr")
plot(ROCR.perf4, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC4 <- performance(ROCR.pred4, "auc")
AUC4 <- as.numeric(AUC4@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix4<- table(data.test4$E.coli.C.MF.conform, train.predict4 > 0.6)
confusionmatrix4
sensitivity4 <- confusionmatrix4[2,2]/(confusionmatrix4[2,2] + confusionmatrix4[2,1])
accuracy4 <- (confusionmatrix4[1,1] + confusionmatrix4[2,2])/sum(confusionmatrix4)

precision4 <- confusionmatrix4[2,2]/(confusionmatrix4[2,2] + confusionmatrix4[2,1])
recall4 <- confusionmatrix4[2,2]/(confusionmatrix4[2,2] + confusionmatrix4[1,2])
f1score4 <- 2/(1/recall3 + 1/precision4)
falsepositive4 <- confusionmatrix4[1,2]/(confusionmatrix4[1,2] + confusionmatrix4[1,1])
```

# **model5 [SALinsitu.ppt]**

### Creating model5
```{r echo = F}
data.train5 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F)
model5 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt, data = data.train5, family = "binomial")
summary(model5)
```

### ROC curve

```{r warning = F, echo = F}
data.test5 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F)
testsize5 <- nrow(data.test5)
train.predict5 <- predict(model5, type = "response", newdata = data.test5)

ROCR.pred5 <- prediction(train.predict5, data.test5$E.coli.C.MF.conform)
ROCR.perf5 <- performance(ROCR.pred5, "tpr", "fpr")
plot(ROCR.perf5, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC5 <- performance(ROCR.pred5, "auc")
AUC5 <- as.numeric(AUC5@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix5<- table(data.test5$E.coli.C.MF.conform, train.predict5 > 0.5)
confusionmatrix5
sensitivity5 <- confusionmatrix5[2,2]/(confusionmatrix5[2,2] + confusionmatrix5[2,1])
accuracy5 <- (confusionmatrix5[1,1] + confusionmatrix5[2,2])/sum(confusionmatrix5)

# precision = TP/(TP + FP)
precision5 <- confusionmatrix5[2,2]/(confusionmatrix5[2,2] + confusionmatrix5[2,1])
recall5 <- confusionmatrix5[2,2]/(confusionmatrix5[2,2] + confusionmatrix5[1,2])
f1score5 <- 2/(1/recall5 + 1/precision5)
falsepositive5 <- confusionmatrix5[1,2]/(confusionmatrix5[1,2] + confusionmatrix5[1,1])
```
# Model Comparison

The models are shown below with the variables used in brackets. 

- model1 = [SALinsitu.ppt + Oxygen.Diss.mg.l]
- model2 = [SALinsitu.ppt + Oxygen.Diss.mg.l*season]
- model3 = [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange + temp.ecolirange]
- model4 = [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange]
- model5 = [SALinsitu.ppt]

Several metrics were saved from the models and are tabulated below for comparison. 
```{r echo = F}
parameter <- c("test size", "AUC of ROC", "sensitivity", "falsepositive", "f1score", "accuracy")
modelresults1 <- c(testsize1, AUC1, sensitivity1, falsepositive1, f1score1, accuracy1)
modelresults2 <- c(testsize2, AUC2, sensitivity2, falsepositive2, f1score2, accuracy2)
modelresults3 <- c(testsize3, AUC3, sensitivity3, falsepositive3, f1score3, accuracy3)
modelresults4 <- c(testsize4, AUC4, sensitivity4, falsepositive4, f1score4, accuracy4)
modelresults5 <- c(testsize5, AUC5, sensitivity5, falsepositive5, f1score5, accuracy5)
comparison <- as.data.frame(rbind(modelresults1, modelresults2, modelresults3, modelresults4, modelresults5))
colnames(comparison) <- parameter
rownames(comparison) <- c("model1", "model2", "model3", "model4", "model5")
comparison
```

Each of the metrics used for comparison are detailed below.

**Test Size** - Ensures that the sample size is large enough to get statistically significant results.

**False Positive Rate** - FP/(TN + FP): This is the rate at which a water sample is incorrectly classified as safe. It's important for this value to be as low as possible, in order to minimize how often people are exposed to unsafe levels of e. coli. Also called fall-out rate, and is equal to 1 - true negative rate (aka specificity)

**Sensitivity** - TP/(TP + FN): This a metric to show how often people will be unecessarily be kept away from water.

**Accuracy** - (TP + TN)/(TP + TN + FP + FN): Is this redundant with f1 score? 

**f1 score** - 2*TP/(2*TP + FP + FN), or the harmonic mean of precision and sensitivity (aka recall). 

### Evaluation of each model

**model1** - Simple baseline model upon which to improve.

**model2** - Relative to model1, model2 has a 1% higher false positive rate, but also a 3% higher sensitivity, 1% higher f1 score, and 1% higher accuracy: a worthwhile trade-off. This seems to be the best model.

**model3** - Drastic drop in f1 score, but not of accuracy! What does this mean specifically?... TP is relatively small compared to FP and FN, whereas TN was significantly large and contributed to the normal-looking value of accuracy. This model likewise has a signiciantly lower sensitivity, meaning that areas will be declared unsafe more often than necessary... possibly leading to people disregarding the warnings and swimming in risky water because they think it's not very likely to have high e. coli. 

**model4** - Same as model3.

**model5** - Much higher accuracy, but at the cost of an unacceptably high false positive rate of 0.20. Model5 isn't the best because public safety is paramount for this project.

### Conclusion

Ultimately, the optimal model tested was model2, which combines the variables of salinity, dissolved oxygen, and season to predict whether a water sample will have an e. coli concentration above the safety limit of 900 no/100ml with an accuray of 79.2% and a minimal false positive rate of 2.0%. With this model, it's possible to reasonably predict when e. coli levels in water are unsafe, giving would-be swimmers an advanced notice. With only the salinity and the dissolved oxygen, which are both easily tested phsyical properties, results can come in far sooner than results can come in from a biological test for the concentration of e. coli, which requires time for bacteria to grow and multiply. Going forward, a way that this model can be improved upon is by testing salinity and dissolved oxygen for all samples testd. This would drastically increase the sample size and the statistical reliability of the model. This model has been somewhat successful with the water quality data of the United Kingdom, but this same process of data munging, exploratory analysis, and machine learning can be applied to any locations water sources. An interesting area of study could be whether salinity, dissolved oxygen, and season are also the predictor variables for e. coli concentration in other locations across the world.

