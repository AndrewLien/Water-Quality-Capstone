---
title: "3-modeling"
author: "Andrew Lien"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo = F, message = F, include = F}
# Setup
library(dplyr)
library(tidyr)
library(magrittr)
library(caTools)
library(ggplot2)
library(ROCR)
library(effects)
water.ecoli <- read.csv("water.ecoli.csv", stringsAsFactors = F)
water.ecoli$materialtype %<>% as.factor()
water.ecoli$time %<>% as.POSIXct(format = "%Y-%m-%dT%H:%M:%S")
water.ecoli$O.Diss..sat.. <- NULL
```

# **Setup**

### Feature Engineering 

Some variables need to be modified before including them in the logistical regression model.

1. time (value) -> seasons (4-level factor)
```{r}
water.ecoli$season <- substr(water.ecoli$time, 6, 7)
water.ecoli$season <- gsub(pattern = "09|10|11", replacement = "fall", x = water.ecoli$season)
water.ecoli$season <- gsub(pattern = "12|01|02", replacement = "winter", x = water.ecoli$season)
water.ecoli$season <- gsub(pattern = "03|04|05", replacement = "spring", x = water.ecoli$season)
water.ecoli$season <- gsub(pattern = "06|07|08", replacement = "summer", x = water.ecoli$season)
```

2. pH.phunits (value) -> whether the value is within 2 standard deviations of the mean (TRUE/FALSE)
```{r}
# The plot below shows that the majority of non-conforming e. ocli measurements are close to the mean of the group, forming a pattern that resembles a normal distribution.
ggplot(water.ecoli, aes(x = pH.phunits,  y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) + geom_point(alpha = 0.3)

# Dividing pH.phunits and Temp.Water.cel into 2 sections each: within mean +/- sd of non-conforming samples. This is because both of these variables exhibit a normal distribution in relation to e. coli concentration.
nonconform.pH <- filter(water.ecoli, is.na(water.ecoli$pH.phunits) == F & water.ecoli$E.coli.C.MF.conform == F)
nonconform.pH.mean <- mean(nonconform.pH$pH.phunits)
nonconform.pH.sd <- sd(nonconform.pH$pH.phunits)
water.ecoli$pH.ecolirange <- ifelse(water.ecoli$pH.phunits < nonconform.pH.mean + 2*nonconform.pH.sd & water.ecoli$pH.phunits > nonconform.pH.mean - 2*nonconform.pH.sd, T, F)
```

3. Temp.Water.cel (value) -> whether the value is within 2 standard deviations of the median (TRUE/FALSE). Median is used here instead of mean because Temp.Water.cel versus E.coli.C.MF.no.100ml has a negatively skewed normal distribution.
```{r}
# The plot below shows that the majority of non-conforming e. ocli measurements are close to the mean of the group, forming a pattern that resembles a negatively skewed normal distribution.
ggplot(water.ecoli, aes(x = Temp.Water.cel,  y = E.coli.C.MF.no.100ml, color = E.coli.C.MF.conform)) + geom_point(alpha = 0.3)

nonconform.temp <- filter(water.ecoli, is.na(water.ecoli$Temp.Water.cel) == F & water.ecoli$E.coli.C.MF.conform == F)
nonconform.temp.mean <- median(nonconform.temp$Temp.Water.cel)
# Median is used instead of mean because this is a negatively skewed normal distribution: the median is closer to the maximum of the arch of the normal distribution than the mean. 
nonconform.temp.sd <- sd(nonconform.temp$Temp.Water.cel)
water.ecoli$temp.ecolirange <- ifelse(water.ecoli$Temp.Water.cel < nonconform.temp.mean + 2*nonconform.temp.sd & water.ecoli$Temp.Water.cel > nonconform.temp.mean - 2*nonconform.temp.sd, T, F)
```

### Normalization

Because many of the variables are in different units, the data needs to be normalized before a meaningful logistical regression model can be built.

```{r}
mean <- mapply(water.ecoli[,7:17], FUN = "mean", na.rm = T)
stdev <- mapply(water.ecoli[,7:17], FUN = "sd", na.rm = T)
water.ecoli[,7:17] %<>% sweep(., 2, FUN = "-", mean) %>% sweep(., 2, FUN = "/", stdev)
```

### Splitting the dataset into training and testing sets
```{r}
set.seed(123)
split.labels <- sample.split(Y = water.ecoli[,1], SplitRatio = 1/2)
data.train <- subset(water.ecoli, split.labels == T)
data.test <- subset(water.ecoli, split.labels == F)
```

**The model generation and evaluation process is the same for each of the models, so the full code is shown only for model1, and only the results are shown for the following models. At the very end of this file is a summary table that compares significant aspects of each model.**

# **model1 [SALinsitu.ppt + Oxygen.Diss.mg.l]**

Different models are compared to see which gets the lowest AIC. This is done with a limited number of variables to 1) avoid overfitting and 2) to keepas many data opints as possible. Each row has values only for certain variables, and the model only takes rows as data points that have a value for every value, so by increasing the number of variables included in the model, the data size will decrease drastically. 
```{r}
# To be able to compare the raw data set and the prediction, they need to be the same length. Since the glm() excludes rows that have NA in any of the specified variables, the raw data needes to be filtered to only rows that fit that criteria. Problem with this is that if there are too many criteria included, then there will be very few rows that match the criteria.
data.train1 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F)

# Decent model with only two variables: SALinsitu.ppt and Oxygen.Diss.mg.l.
model1 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l, data = data.train1, family = "binomial")
summary(model1)
AIC1 <- AIC(model1)
```

```{r eval = F}
# Some variable combinations that didn't work are included here.

# When BOD.ATU.mg.l, Nitrite.N.mg.l, or Nitrate.N.mg.l are used in a model, the error "fitted probabilities numericaly 0 or 1 occurred" occurs. These variables will not be used in modeling.
```

### ROC curve

```{r warning = F}
# predict() can't be used if there are NAs included, so rows with NA in either SALinsitu.ppt or Oxygen.Diss.mg.l need to be filtered out. To test the out-of-sample performance of this model, predict() is used on the data.test, which was not used to create the model. 
data.test1 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F)
# predict() can now be used. 
testsize1 <- nrow(data.test1)
train.predict1 <- predict(model1, type = "response", newdata = data.test1)

ROCR.pred1 <- prediction(train.predict1, data.test1$E.coli.C.MF.conform)
ROCR.perf1 <- performance(ROCR.pred1, "tpr", "fpr")
plot(ROCR.perf1, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj = c(-0.2, 1.7))
# According to the plot, t = 0.7 yields the more desirable balance of sensitivity and specificity. In this case, higher sensitivity is desired because a false negative leads to higher than expected e. coli levels and the associated public health risks.

# ROC area under curve
AUC1 <- performance(ROCR.pred1, "auc")
AUC1 <- as.numeric(AUC1@y.values)
```

### Confusion Matrix

```{r}
# Confusion matrix with t = 0.7
confusionmatrix1<- table(data.test1$E.coli.C.MF.conform, train.predict1 > 0.7)
confusionmatrix1
sensitivity1 <- confusionmatrix1[2,2]/(confusionmatrix1[2,2] + confusionmatrix1[2,1])
specificity1 <- confusionmatrix1[1,1]/(confusionmatrix1[1,1] + confusionmatrix1[1,2])
accuracy1 <- (confusionmatrix1[1,1] + confusionmatrix1[2,2])/sum(confusionmatrix1)
sensitivity1
specificity1
accuracy1
```

### F1-score

```{r}
# F1-score = 2/(1/recall + 1/precision)
# precision = TP/(TP + FP)
# recall = TP/(TP + FN)

precision1 <- confusionmatrix1[2,2]/(confusionmatrix1[2,2] + confusionmatrix1[2,1])
recall1 <- confusionmatrix1[2,2]/(confusionmatrix1[2,2] + confusionmatrix1[1,2])
f1score1 <- 2/(1/recall1 + 1/precision1)
f1score1
```

# **model2 [SALinsitu.ppt + Oxygen.Diss.mg.l*season]**

### Creating model2
```{r echo = F}
data.train2 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F)

model2 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l*season, data = data.train2, family = "binomial")
AIC2 <- AIC(model2)
summary(model2)
```

### ROC curve

```{r warning = F, echo = F}
data.test2 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F & is.na(data.test$season) == F)
testsize2 <- nrow(data.test2)
train.predict2 <- predict(model2, type = "response", newdata = data.test2)

ROCR.pred2 <- prediction(train.predict2, data.test2$E.coli.C.MF.conform)
ROCR.perf2 <- performance(ROCR.pred2, "tpr", "fpr")
plot(ROCR.perf2, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC2 <- performance(ROCR.pred2, "auc")
AUC2 <- as.numeric(AUC2@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix2<- table(data.test2$E.coli.C.MF.conform, train.predict2 > 0.6)
confusionmatrix2
sensitivity2 <- confusionmatrix2[2,2]/(confusionmatrix2[2,2] + confusionmatrix2[2,1])
specificity2 <- confusionmatrix2[1,1]/(confusionmatrix2[1,1] + confusionmatrix2[1,2])
accuracy2 <- (confusionmatrix2[1,1] + confusionmatrix2[2,2])/sum(confusionmatrix2)

precision2 <- confusionmatrix2[2,2]/(confusionmatrix2[2,2] + confusionmatrix2[2,1])
recall2 <- confusionmatrix2[2,2]/(confusionmatrix2[2,2] + confusionmatrix2[1,2])
f1score2 <- 2/(1/recall2 + 1/precision2)
```

# **model3 [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange + temp.ecolirange]**

### Creating model3
```{r echo = F}
data.train3 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F & is.na(data.train$pH.ecolirange) == F & is.na(data.train$temp.ecolirange) == F)

model3 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange + temp.ecolirange, data = data.train3, family = "binomial")
summary(model3)
AIC3 <- AIC(model3)
```

### ROC curve

```{r warning = F, echo = F}
data.test3 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F & is.na(data.test$pH.ecolirange) == F & is.na(data.test$temp.ecolirange) == F)
testsize3 <- nrow(data.test3)
train.predict3 <- predict(model3, type = "response", newdata = data.test3)

ROCR.pred3 <- prediction(train.predict3, data.test3$E.coli.C.MF.conform)
ROCR.perf3 <- performance(ROCR.pred3, "tpr", "fpr")
plot(ROCR.perf3, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC3 <- performance(ROCR.pred3, "auc")
AUC3 <- as.numeric(AUC3@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix3<- table(data.test3$E.coli.C.MF.conform, train.predict3 > 0.5)
confusionmatrix3
sensitivity3 <- confusionmatrix3[2,2]/(confusionmatrix3[2,2] + confusionmatrix3[2,1])
specificity3 <- confusionmatrix3[1,1]/(confusionmatrix3[1,1] + confusionmatrix3[1,2])
accuracy3 <- (confusionmatrix3[1,1] + confusionmatrix3[2,2])/sum(confusionmatrix3)

precision3 <- confusionmatrix3[2,2]/(confusionmatrix3[2,2] + confusionmatrix3[2,1])
recall3 <- confusionmatrix3[2,2]/(confusionmatrix3[2,2] + confusionmatrix3[1,2])
f1score3 <- 2/(1/recall3 + 1/precision3)
```

# **model4 [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange]**

### Creating model4
```{r echo = F}
data.train4 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F & is.na(data.train$Oxygen.Diss.mg.l) == F & is.na(data.train$pH.ecolirange) == F)
model4 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange, data = data.train4, family = "binomial")
AIC4 <- AIC(model4)
summary(model4)
```

### ROC curve

```{r warning = F, echo = F}
data.test4 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F & is.na(data.test$Oxygen.Diss.mg.l) == F & is.na(data.test$pH.ecolirange) == F)
testsize4 <- nrow(data.test4)
train.predict4 <- predict(model4, type = "response", newdata = data.test4)

ROCR.pred4 <- prediction(train.predict4, data.test4$E.coli.C.MF.conform)
ROCR.perf4 <- performance(ROCR.pred4, "tpr", "fpr")
plot(ROCR.perf4, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC4 <- performance(ROCR.pred4, "auc")
AUC4 <- as.numeric(AUC4@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix4<- table(data.test4$E.coli.C.MF.conform, train.predict4 > 0.6)
confusionmatrix4
sensitivity4 <- confusionmatrix4[2,2]/(confusionmatrix4[2,2] + confusionmatrix4[2,1])
specificity4 <- confusionmatrix4[1,1]/(confusionmatrix4[1,1] + confusionmatrix4[1,2])
accuracy4 <- (confusionmatrix4[1,1] + confusionmatrix4[2,2])/sum(confusionmatrix4)

precision4 <- confusionmatrix4[2,2]/(confusionmatrix4[2,2] + confusionmatrix4[2,1])
recall4 <- confusionmatrix4[2,2]/(confusionmatrix4[2,2] + confusionmatrix4[1,2])
f1score4 <- 2/(1/recall3 + 1/precision4)
```

# **model5 [SALinsitu.ppt]**

### Creating model5
```{r echo = F}
data.train5 <- filter(data.train, is.na(data.train$SALinsitu.ppt) == F)
model5 <- glm(E.coli.C.MF.conform ~ SALinsitu.ppt, data = data.train5, family = "binomial")
AIC5 <- AIC(model5)
summary(model5)
```

### ROC curve

```{r warning = F, echo = F}
data.test5 <- filter(data.test, is.na(data.test$SALinsitu.ppt) == F)
testsize5 <- nrow(data.test5)
train.predict5 <- predict(model5, type = "response", newdata = data.test5)

ROCR.pred5 <- prediction(train.predict5, data.test5$E.coli.C.MF.conform)
ROCR.perf5 <- performance(ROCR.pred5, "tpr", "fpr")
plot(ROCR.perf5, colorize = TRUE, print.cutoffs.at = seq(0, 1, 0.1), text.adj
     = c(-0.2, 1.7))

AUC5 <- performance(ROCR.pred5, "auc")
AUC5 <- as.numeric(AUC5@y.values)
```

### Confusion Matrix

```{r echo = F}
confusionmatrix5<- table(data.test5$E.coli.C.MF.conform, train.predict5 > 0.5)
confusionmatrix5
sensitivity5 <- confusionmatrix5[2,2]/(confusionmatrix5[2,2] + confusionmatrix5[2,1])
specificity5 <- confusionmatrix5[1,1]/(confusionmatrix5[1,1] + confusionmatrix5[1,2])
accuracy5 <- (confusionmatrix5[1,1] + confusionmatrix5[2,2])/sum(confusionmatrix5)

precision5 <- confusionmatrix5[2,2]/(confusionmatrix5[2,2] + confusionmatrix5[2,1])
recall5 <- confusionmatrix5[2,2]/(confusionmatrix5[2,2] + confusionmatrix5[1,2])
f1score5 <- 2/(1/recall5 + 1/precision5)
```
# Model Comparison

model1 = [SALinsitu.ppt + Oxygen.Diss.mg.l]

model2 = [SALinsitu.ppt + Oxygen.Diss.mg.l*season]

model3 = [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange + temp.ecolirange]

model4 = [SALinsitu.ppt + Oxygen.Diss.mg.l + pH.ecolirange]

model5 = [SALinsitu.ppt]

```{r echo = F}
parameter <- c("test size", "AIC", "AUC of ROC", "sensitivity", "specificity", "f1score", "accuracy")
modelresults1 <- c(testsize1, AIC1, AUC1, sensitivity1, specificity1, f1score1, accuracy1)
modelresults2 <- c(testsize2, AIC2, AUC2, sensitivity2, specificity2, f1score2, accuracy2)
modelresults3 <- c(testsize3, AIC3, AUC3, sensitivity3, specificity3, f1score3, accuracy3)
modelresults4 <- c(testsize4, AIC4, AUC4, sensitivity4, specificity4, f1score4, accuracy4)
modelresults5 <- c(testsize5, AIC5, AUC5, sensitivity5, specificity5, f1score5, accuracy5)
comparison <- as.data.frame(rbind(modelresults1, modelresults2, modelresults3, modelresults4, modelresults5))
colnames(comparison) <- parameter
rownames(comparison) <- c("model1", "model2", "model3", "model4", "model5")
comparison
```

note to self: AIC actually has no meaning here. Each model is using a different data set (different filtrations of the same data set). This metric can be removed.